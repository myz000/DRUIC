{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "# import tensorflow.keras as keras\n",
    "# import tensorflow.keras.backend.tensorflow_backend as KTF\n",
    " \n",
    "# config = tf.ConfigProto()  \n",
    "# config.gpu_options.allow_growth=True  \n",
    "# session = tf.Session(config=config)\n",
    " \n",
    "# KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Hypers import *\n",
    "from Utils import *\n",
    "from Preprocessing import *\n",
    "from Generator import *\n",
    "from Models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIND_type = 'small'\n",
    "data_path = '/home/myz/model/recommendations/Multi_Interest_News_Recommendation/dataset/MIND'+MIND_type\n",
    "# data_path = '/data/Multi_Interest_News_Recommendation/dataset/MIND'+MIND_type\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'train_behaviors.tsv')\n",
    "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding_all.npy\")\n",
    "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict_all.pkl\")\n",
    "vertDict_file = os.path.join(data_path, \"utils\", \"vert_dict.pkl\")\n",
    "subvertDict_file = os.path.join(data_path, \"utils\", \"subvert_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\", r'MINR.yaml')\n",
    "\n",
    "valid_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'train', r'val_behaviors.tsv')\n",
    "test_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "test_behaviors_file = os.path.join(data_path, 'valid', r'test_behaviors.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = train_news_file\n",
    "# embedding_path = '/data/pretrained_model/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news,news_index,category_dict,subcategory_dict,word_dict,content_dict,entity_dict = read_news([train_news_file,test_news_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_input(news,news_index,category_dict,subcategory_dict,word_dict,content_dict,entity_dict):\n",
    "    news_num=len(news)+1\n",
    "    news_title=np.zeros((news_num,MAX_TITLE),dtype='int32')\n",
    "    news_vert=np.zeros((news_num,),dtype='int32')\n",
    "    news_subvert=np.zeros((news_num,),dtype='int32')\n",
    "    news_entity = np.zeros((news_num,MAX_ENTITY),dtype='int32')\n",
    "    news_content = np.zeros((news_num,MAX_CONTENT),dtype='int32')\n",
    "    \n",
    "    news_origin_title = [\"\"]*news_num\n",
    "    \n",
    "    for key in news:    \n",
    "        vert,subvert,title,entity,content = news[key]\n",
    "        doc_index=news_index[key]\n",
    "        news_origin_title[doc_index]=title\n",
    "        \n",
    "        news_vert[doc_index]=category_dict[vert]\n",
    "        news_subvert[doc_index]=subcategory_dict[subvert]\n",
    "        \n",
    "        for word_id in range(min(MAX_TITLE,len(title))):\n",
    "            news_title[doc_index,word_id]=word_dict[title[word_id]]\n",
    "        \n",
    "        for entity_id in range(min(MAX_ENTITY,len(entity))):\n",
    "            news_entity[doc_index,entity_id]=entity_dict[entity[entity_id]]\n",
    "\n",
    "        for content_id in range(min(MAX_ENTITY,len(content))):\n",
    "            if not content[content_id] in content_dict:\n",
    "                continue\n",
    "            news_content[doc_index,content_id]=content_dict[content[content_id]]\n",
    "\n",
    "    return news_title,news_vert,news_subvert,news_entity,news_content,news_origin_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title,news_vert,news_subvert,news_entity,news_content,news_origin_title=get_doc_input(news,news_index,category_dict,subcategory_dict,word_dict,content_dict,entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65239, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = '/home/myz/model/recommendations/pre-trained-model/glove.840B.300d.txt'\n",
    "title_word_embedding_matrix, have_word = load_matrix(embedding_path,word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载预训练bert\n",
    "\n",
    "若不需要bert直接到加载category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, TFBertModel\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = TFBertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理新闻bert预训练表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "News_pre_emd = np.zeros((len(news)+1,768),dtype='float32')\n",
    "Origin_title = [\"\"]*(len(news)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 49846/65238 [1:14:55<23:07, 11.09it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keys_list = list(news.keys())\n",
    "\n",
    "for i in tqdm(range(len(keys_list))):\n",
    "# for k,v in news.items():\n",
    "    k=keys_list[i]\n",
    "    v=news[k]\n",
    "    text=' '.join(v[2])\n",
    "    encoded_input = tokenizer(text, return_tensors='tf')\n",
    "    output = model(encoded_input)\n",
    "    News_pre_emd[news_index[k]]=output.pooler_output.numpy()[0]\n",
    "    Origin_title[news_index[k]]=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65239, 768)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_pre_emd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_path, \"utils\", \"news_bert_embedding.npy\"),News_pre_emd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载新闻bert表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "News_pre_emd = np.load(os.path.join(data_path, \"utils\", \"news_bert_embedding.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65239, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_pre_emd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexx = np.array(range(65239),dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_word_embedding_matrix, have_word = load_matrix(embedding_path,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# entity_emb_matrix = load_entity_embedding(os.path.join(data_path,\"title_entity_emb.pkl\"),entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'title_word_embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-94b7ef7c5c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitle_word_embedding_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'title_word_embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "title_word_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理category embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lifestyle 1\n",
      "health 2\n",
      "news 3\n",
      "sports 4\n",
      "weather 5\n",
      "entertainment 6\n",
      "autos 7\n",
      "travel 8\n",
      "foodanddrink 9\n",
      "tv 10\n",
      "finance 11\n",
      "movies 12\n",
      "video 13\n",
      "music 14\n",
      "kids 15\n",
      "middleeast 16\n",
      "northamerica 17\n",
      "games 18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vert_embedding_matrix = np.zeros((19,300),dtype='float32')\n",
    "for k,v in category_dict.items():\n",
    "    print(k,v)\n",
    "    if v==9 or v==16 or v==17:\n",
    "        continue\n",
    "    vert_embedding_matrix[v]=title_word_embedding_matrix[word_dict[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_embedding_matrix[9]=(title_word_embedding_matrix[word_dict['food']]+title_word_embedding_matrix[word_dict['and']]+title_word_embedding_matrix[word_dict['drink']])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_embedding_matrix[16]=(title_word_embedding_matrix[word_dict['middle']]+title_word_embedding_matrix[word_dict['east']])#+title_word_embedding_matrix[word_dict['drink']])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_embedding_matrix[17]=(title_word_embedding_matrix[word_dict['north']]+title_word_embedding_matrix[word_dict['america']])#+title_word_embedding_matrix[word_dict['drink']])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_path, \"utils\", \"vert_word_embedding.npy\"),vert_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载category 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载vert word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vert_embedding_matrix = np.load(os.path.join(data_path, \"utils\", \"vert_word_embedding.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_vert_layer(vert_embedding_matrix):\n",
    "#     vert_input = Input(shape=(1,), dtype='int32')\n",
    "#     vert_word_embedding_layer = Embedding(vert_embedding_matrix.shape[0], vert_embedding_matrix.shape[1], weights=[vert_embedding_matrix],trainable=False)\n",
    "#     vert_emb = vert_word_embedding_layer(vert_input)\n",
    "#     vertEncodert = Model(vert_input, vert_emb)\n",
    "#     return vertEncodert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vert_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义信息输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只考虑title\n",
    "# news_info = np.concatenate([news_title,news_entity,news_vert.reshape((-1,1))],axis=-1)\n",
    "# news_info = np.concatenate([news_title],axis=-1)\n",
    "# news_info = np.concatenate([indexx.reshape((-1,1)),news_vert.reshape((-1,1))],axis=-1)\n",
    "\n",
    "news_info = np.concatenate([news_title,news_vert.reshape((-1,1))],axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Weighter(Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(Weighter, self).__init__(**kwargs)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         trainable = False\n",
    "#         self.w = self.add_weight(name='w',\n",
    "#                                   shape=(1,),\n",
    "#                                   initializer=tensorflow.keras.initializers.Constant(value=0),\n",
    "#                                   trainable=trainable)\n",
    "\n",
    "#         super(Weighter, self).build(input_shape)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         return self.w * x\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_SIZE=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttentivePooling(dim1, dim2):\n",
    "    vecs_input = Input(shape=(dim1, dim2), dtype='float32')\n",
    "    user_vecs = Dropout(0.2)(vecs_input)\n",
    "    user_att = Dense(200, activation='tanh')(user_vecs)\n",
    "    user_att = layers.Flatten()(Dense(1)(user_att))\n",
    "    user_att = Activation('softmax')(user_att)\n",
    "    user_vec = keras.layers.Dot((1, 1))([user_vecs, user_att])\n",
    "    model = Model(vecs_input, user_vec)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_encoder(title_word_embedding_matrix):\n",
    "    news_input = Input(shape=(TITLE_SIZE,), dtype='int32')\n",
    "\n",
    "    title_word_embedding_layer = Embedding(title_word_embedding_matrix.shape[0], \n",
    "                                           title_word_embedding_matrix.shape[1],\n",
    "                                           weights=[title_word_embedding_matrix], trainable=True)\n",
    "    word_vecs = title_word_embedding_layer(news_input)\n",
    "    droped_vecs = Dropout(0.2)(word_vecs)\n",
    "    word_rep = Attention(20, 20)([droped_vecs] * 3)\n",
    "    droped_rep = Dropout(0.2)(word_rep)\n",
    "    title_vec = AttentivePooling(30, 400)(droped_rep)\n",
    "\n",
    "    #vec = title_vec\n",
    "    #vec = keras.layers.Dense(300)(vec)\n",
    "\n",
    "    sentEncodert = Model(news_input, title_vec)\n",
    "    return sentEncodert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyAttention(Layer):\n",
    "    def __init__(self, hidden_dim, num_context, **kwargs):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_context=num_context\n",
    "        super(PolyAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        trainable = True\n",
    "        self.context = self.add_weight(name='c',\n",
    "                                  shape=(self.num_context,self.hidden_dim),\n",
    "                                  initializer=keras.initializers.glorot_uniform(seed=0),\n",
    "                                  trainable=trainable,\n",
    "                                  regularizer = keras.regularizers.l2(0.0001))\n",
    "        \n",
    "        self.projection = layers.Dense(self.hidden_dim,activation='tanh',use_bias=False)  \n",
    "        \n",
    "        self.lamada = self.add_weight(name='w',\n",
    "                                  shape=(1,),\n",
    "                                  initializer=tensorflow.keras.initializers.Constant(value=0),\n",
    "                                  trainable=trainable)\n",
    "\n",
    "        super(PolyAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, category_bias,att_mask = inputs\n",
    "        # x - 输入向量 (?,his_size,dim)\n",
    "        # category_bias 计算出的与候选新闻的 category的余弦相似度  (?,his_size,1)\n",
    "        # att_mask  （?,his_size）\n",
    "        \n",
    "        proj = self.projection(x)  #(?,his_size,hidden_dim)\n",
    "        #category_bias = tf.expand_dims(category_bias,-1)\n",
    "        \n",
    "        weights = tf.matmul(proj, self.context, transpose_b=True) + self.lamada*category_bias\n",
    "        #(?,his_size,num_context)\n",
    "        print(\"weights:\",weights)\n",
    "        weights = tf.transpose(weights,[0,2,1]) #(?,num_context,his_size)\n",
    "        masks = tf.expand_dims(att_mask,1) #(?,1,his_size)\n",
    "        \n",
    "        weights = weights - (1 - masks) * 1e12\n",
    "        weights = tf.nn.softmax(weights, axis=-1) #(?, num_context, his_size)\n",
    "        \n",
    "        poly_repr = tf.matmul(weights,x) #(?, num_context, dim)\n",
    "                \n",
    "        return poly_repr\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0][0],self.num_context,input_shape[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeMasking(layers.Layer):\n",
    "    \"\"\"Compute if inputs contains zero value.\n",
    "\n",
    "    Returns:\n",
    "        bool tensor: True for values not equal to zero.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ComputeMasking, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        mask = K.not_equal(inputs, 0)\n",
    "        return K.cast(mask, K.floatx())\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def get_config(self):   \n",
    "        config = super().get_config().copy()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Target_weight(Layer):\n",
    "    def __init__(self, hidden, **kwargs):\n",
    "        self.hidden = hidden\n",
    "        super(Target_weight, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.linear = layers.Dense(self.hidden,activation='tanh',use_bias=False)\n",
    "        \n",
    "        super(Target_weight, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        query, key, value = x\n",
    "        # query - user (?,c,dim)\n",
    "        # key - candidate (?,dim,1)\n",
    "        # value - score (?,c)\n",
    "        proj = self.linear(query) #(?,c,dim)\n",
    "        att = tf.matmul(proj, key) #(?,c,1)\n",
    "        att = tf.squeeze(att,-1) #(?,c)\n",
    "        att = tf.nn.softmax(att,-1) #(?,c)\n",
    "        scores = tf.reduce_sum(tf.multiply(att,value),-1,keep_dims=True) #(?,1)\n",
    "           \n",
    "        return scores\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inner_model(Layer):\n",
    "    def __init__(self,news_encoder, vert_embedding_matrix, num_context, **kwargs):\n",
    "        self.vert_encoder = Embedding(vert_embedding_matrix.shape[0], \n",
    "                               vert_embedding_matrix.shape[1],\n",
    "                               weights=[vert_embedding_matrix], trainable=True)\n",
    "        self.num_context = num_context\n",
    "        self.poly_attn = PolyAttention(200,num_context)\n",
    "        self.news_encoder = news_encoder\n",
    "        self.vert_dropout = layers.Dropout(0.2)\n",
    "        self.Target_weight = Target_weight(400)\n",
    "\n",
    "        super(Inner_model, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        trainable = False\n",
    "        \n",
    "        self.w = self.add_weight(name='w',\n",
    "                                  shape=(1,),\n",
    "                                  initializer=tensorflow.keras.initializers.Constant(value=0),\n",
    "                                  trainable=trainable)\n",
    "\n",
    "        super(Inner_model, self).build(input_shape)\n",
    "\n",
    "    def get_multiple_user_pre(self,user_clicked_title, user_clicked_vert, candidate_vert,user_mask):\n",
    "        his_title_emd = TimeDistributed(self.news_encoder)(user_clicked_title)\n",
    "        \n",
    "        his_vert_emd = self.vert_encoder(user_clicked_vert)\n",
    "        his_vert_emd = self.vert_dropout(his_vert_emd)\n",
    "        his_vert_emd = tf.math.l2_normalize(his_vert_emd, -1) #(?,50,300)\n",
    "        \n",
    "        can_vert_emd = self.vert_encoder(candidate_vert)\n",
    "        can_vert_emd = self.vert_dropout(can_vert_emd)\n",
    "        can_vert_emd = tf.math.l2_normalize(can_vert_emd, -1)  #(?,300)\n",
    "        can_vert_emd = tf.expand_dims(can_vert_emd,1) #(?,1,300)\n",
    "        \n",
    "        vert_cosine = tf.matmul(his_vert_emd,can_vert_emd,transpose_b=True) #(?,50,1)\n",
    "        \n",
    "        print(his_title_emd,vert_cosine,user_mask)\n",
    "        mul_user_interests = self.poly_attn([his_title_emd,vert_cosine,user_mask])\n",
    "        return mul_user_interests\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        user_clicked_title, candidate_title, user_clicked_vert, candidate_vert, user_mask = x\n",
    "        mul_user_interests = self.get_multiple_user_pre(user_clicked_title, user_clicked_vert, candidate_vert, user_mask)\n",
    "        \n",
    "        can_emd = self.news_encoder(candidate_title)       \n",
    "        can_emd = tf.expand_dims(can_emd,-1) #(?,300,1)\n",
    "        scores = tf.matmul(mul_user_interests,can_emd) #(?,32,1)\n",
    "        scores = tf.squeeze(scores,axis=-1) #(?,32)\n",
    "        \n",
    "        print(mul_user_interests,can_emd,scores)\n",
    "        final_scores = self.Target_weight([mul_user_interests,can_emd,scores])\n",
    "        print(\"final_scores:\",final_scores)\n",
    "        \n",
    "        return final_scores,mul_user_interests\n",
    "    \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0],1),(input_shape[0][0],self.num_context,input_shape[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_miner(news_encoder,vert_embedding_matrix):\n",
    "    inner_model = Inner_model(news_encoder,vert_embedding_matrix,32)\n",
    "    \n",
    "    clicked_title_input = Input(shape=(MAX_CLICK,TITLE_SIZE+1,), dtype='int32')    \n",
    "    title_inputs = Input(shape=(TITLE_SIZE+1,),dtype='int32') \n",
    "\n",
    "        \n",
    "    u_input = keras.layers.Lambda(lambda x:x[:,:,:TITLE_SIZE])(clicked_title_input)  # (?,50,30)\n",
    "    c_input = keras.layers.Lambda(lambda x:x[:,:TITLE_SIZE])(title_inputs)  # (?,30)\n",
    "    \n",
    "    \n",
    "    clicked_news_cat_input = keras.layers.Lambda(lambda x:x[:,:,TITLE_SIZE])(clicked_title_input)\n",
    "    title_cat_input = keras.layers.Lambda(lambda x:x[:,TITLE_SIZE])(title_inputs)\n",
    "    \n",
    "    user_mask = ComputeMasking()(tf.reduce_sum(u_input,-1))\n",
    "    \n",
    "    [scores,mul_user_pre] = inner_model([u_input,c_input,clicked_news_cat_input,title_cat_input,user_mask])\n",
    "    \n",
    "    model = Model([title_inputs, clicked_title_input], [scores,mul_user_pre])\n",
    "    model1 = Model([title_inputs, clicked_title_input], scores)\n",
    "    \n",
    "    return model,model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(inputs):\n",
    "    dynamic_shape = tf.shape(inputs)\n",
    "    static_shape = inputs.get_shape().as_list()\n",
    "    shape = []\n",
    "    for i, dim in enumerate(static_shape):\n",
    "        shape.append(dim if dim is not None else dynamic_shape[i])\n",
    "\n",
    "    return shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_cosine_similarity(x,y,zero_diagonal):\n",
    "    x_norm = tf.math.l2_normalize(x)  #(?,M,d)\n",
    "    y_norm = tf.math.l2_normalize(y)  #(?,N,d)\n",
    "    distance = tf.matmul(x_norm,y_norm,transpose_b=True)\n",
    "    #distance = tf.matmul(tf.math.divide(x, x_norm), tf.math.divide(y, y_norm),transpose_b=True)#(?,M,N)\n",
    "    if zero_diagonal:\n",
    "        mask = tf.tile(tf.expand_dims(tf.eye(get_shape(x)[1]),0),[get_shape(x)[0],1,1])\n",
    "        distance = distance*(1-mask)\n",
    "        \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(news_embedding_matrix,vert_embedding_matrix):\n",
    "    \n",
    "    MAX_LENGTH = 30    \n",
    "    MAX_CLICK = 50\n",
    "    \n",
    "    news_encoder = get_doc_encoder(title_word_embedding_matrix)\n",
    "    \n",
    "    miner,inner_model = get_miner(news_encoder,vert_embedding_matrix)\n",
    "\n",
    "    clicked_title_input = Input(shape=(MAX_CLICK,MAX_LENGTH+1,), dtype='int32')    \n",
    "    title_inputs = Input(shape=(1+npratio,MAX_LENGTH+1,),dtype='int32') \n",
    "    \n",
    "    \n",
    "    scores = []\n",
    "    user_loss = []\n",
    "    for i in range(1+npratio):\n",
    "        news_vec = keras.layers.Lambda(lambda x:x[:,i,:])(title_inputs)\n",
    "        score,u_pre = miner([news_vec,clicked_title_input])\n",
    "        u_loss = pairwise_cosine_similarity(u_pre,u_pre,True) \n",
    "        print(u_pre)\n",
    "        print(u_loss)\n",
    "        #?,32,768\n",
    "        #?,32\n",
    "        u_loss = tf.reduce_mean(u_loss)\n",
    "        user_loss.append(u_loss)\n",
    "        scores.append(score)\n",
    "        \n",
    "    scores = keras.layers.Concatenate(axis=-1)(scores)\n",
    "    \n",
    "    logits = keras.layers.Activation(keras.activations.softmax,name = 'recommend')(scores)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    #user_loss = keras.layers.Concatenate(axis=-1)(user_loss)\n",
    "    print(user_loss)\n",
    "    user_loss = tf.reduce_mean(user_loss)\n",
    "    print(user_loss)\n",
    "    model = Model([title_inputs, clicked_title_input],logits) # max prob_click_positive\n",
    "    model.add_loss(0.8*user_loss)\n",
    "    model.compile(loss=['categorical_crossentropy'],\n",
    "                  optimizer=Adam(lr=0.00005), \n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model,inner_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 10\n",
    "filter_nums = [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/myz/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/myz/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for t in range(times):\n",
    "    for filter_num in filter_nums:\n",
    "        tf.reset_default_graph()\n",
    "        file = 'Result/'\n",
    "        train_session = read_train_clickhistory(news_index,data_path,'train/train_behaviors.tsv',filter_num)\n",
    "        train_user = parse_user(news_index,train_session)\n",
    "        train_sess, train_user_id, train_label = get_train_input(news_index,train_session)\n",
    "\n",
    "        train_generator = get_hir_train_generator(news_info,train_user['click'],train_user_id,train_sess,train_label,32)\n",
    "\n",
    "        # test_session = read_test_clickhistory_noclk(news_index,data_path,'valid/test_behaviors.tsv')\n",
    "        test_session = read_test_clickhistory(news_index,data_path,'valid/test_behaviors.tsv',filter_num)\n",
    "        test_user = parse_user(news_index,test_session)\n",
    "\n",
    "        test_docids, test_userids, test_labels, test_bound = get_test_input(news_index,test_session)\n",
    "        \n",
    "        model,inter_model = create_model(title_word_embedding_matrix,vert_embedding_matrix)\n",
    "        \n",
    "        model.fit_generator(train_generator,epochs=8)\n",
    "        \n",
    "        test_generator = get_test_generator(news_info,test_docids,test_userids,test_user['click'],32)\n",
    "        predicted_label = inter_model.predict_generator(test_generator,verbose=1)\n",
    "        AUC, MRR, nDCG5, nDCG10 = evaluate(predicted_label,test_labels,test_bound)\n",
    "        \n",
    "        with open(file+'231020_1_filterHis_'+str(filter_num)+'.txt','a+') as f:\n",
    "            f.write(\"\\n-----------\\n\")    \n",
    "            f.write(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+\"\\n\")\n",
    "            f.write(str(AUC)+\" , \"+str(MRR)+\" , \"+str(nDCG5)+\" , \"+str(nDCG10)+\"\\n\\n\")\n",
    "            f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6438759682025859,\n",
       " 0.28878005640707355,\n",
       " 0.31601389977085187,\n",
       " 0.382781956225778)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC, MRR, nDCG5, nDCG10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5064005],\n",
       "       [1.6007793],\n",
       "       [2.3917246],\n",
       "       ...,\n",
       "       [1.9574381],\n",
       "       [1.1135776],\n",
       "       [1.2768797]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/myz/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/myz/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Tensor(\"inner_model/time_distributed/Reshape_1:0\", shape=(?, 50, 400), dtype=float32) Tensor(\"inner_model/MatMul:0\", shape=(?, 50, 1), dtype=float32) Tensor(\"compute_masking/Cast:0\", shape=(?, 50), dtype=float32)\n",
      "weights: Tensor(\"inner_model/poly_attention/add:0\", shape=(?, 50, 32), dtype=float32)\n",
      "Tensor(\"inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32) Tensor(\"inner_model/ExpandDims_1:0\", shape=(?, 400, 1), dtype=float32) Tensor(\"inner_model/Squeeze:0\", shape=(?, 32), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-25-f03456d95f45>:20: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "final_scores: Tensor(\"inner_model/target_weight/Sum:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"model_2/inner_model/time_distributed_1/Reshape_1:0\", shape=(?, 50, 400), dtype=float32) Tensor(\"model_2/inner_model/MatMul:0\", shape=(?, 50, 1), dtype=float32) Tensor(\"model_2/compute_masking/Cast:0\", shape=(?, 50), dtype=float32)\n",
      "weights: Tensor(\"model_2/inner_model/poly_attention/add:0\", shape=(?, 50, 32), dtype=float32)\n",
      "Tensor(\"model_2/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32) Tensor(\"model_2/inner_model/ExpandDims_1:0\", shape=(?, 400, 1), dtype=float32) Tensor(\"model_2/inner_model/Squeeze:0\", shape=(?, 32), dtype=float32)\n",
      "final_scores: Tensor(\"model_2/inner_model/target_weight/Sum:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"model_2/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32)\n",
      "Tensor(\"mul:0\", shape=(?, 32, 32), dtype=float32)\n",
      "Tensor(\"model_2_1/inner_model/time_distributed_2/Reshape_1:0\", shape=(?, 50, 400), dtype=float32) Tensor(\"model_2_1/inner_model/MatMul:0\", shape=(?, 50, 1), dtype=float32) Tensor(\"model_2_1/compute_masking/Cast:0\", shape=(?, 50), dtype=float32)\n",
      "weights: Tensor(\"model_2_1/inner_model/poly_attention/add:0\", shape=(?, 50, 32), dtype=float32)\n",
      "Tensor(\"model_2_1/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32) Tensor(\"model_2_1/inner_model/ExpandDims_1:0\", shape=(?, 400, 1), dtype=float32) Tensor(\"model_2_1/inner_model/Squeeze:0\", shape=(?, 32), dtype=float32)\n",
      "final_scores: Tensor(\"model_2_1/inner_model/target_weight/Sum:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"model_2_1/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32)\n",
      "Tensor(\"mul_1:0\", shape=(?, 32, 32), dtype=float32)\n",
      "Tensor(\"model_2_2/inner_model/time_distributed_3/Reshape_1:0\", shape=(?, 50, 400), dtype=float32) Tensor(\"model_2_2/inner_model/MatMul:0\", shape=(?, 50, 1), dtype=float32) Tensor(\"model_2_2/compute_masking/Cast:0\", shape=(?, 50), dtype=float32)\n",
      "weights: Tensor(\"model_2_2/inner_model/poly_attention/add:0\", shape=(?, 50, 32), dtype=float32)\n",
      "Tensor(\"model_2_2/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32) Tensor(\"model_2_2/inner_model/ExpandDims_1:0\", shape=(?, 400, 1), dtype=float32) Tensor(\"model_2_2/inner_model/Squeeze:0\", shape=(?, 32), dtype=float32)\n",
      "final_scores: Tensor(\"model_2_2/inner_model/target_weight/Sum:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"model_2_2/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32)\n",
      "Tensor(\"mul_2:0\", shape=(?, 32, 32), dtype=float32)\n",
      "Tensor(\"model_2_3/inner_model/time_distributed_4/Reshape_1:0\", shape=(?, 50, 400), dtype=float32) Tensor(\"model_2_3/inner_model/MatMul:0\", shape=(?, 50, 1), dtype=float32) Tensor(\"model_2_3/compute_masking/Cast:0\", shape=(?, 50), dtype=float32)\n",
      "weights: Tensor(\"model_2_3/inner_model/poly_attention/add:0\", shape=(?, 50, 32), dtype=float32)\n",
      "Tensor(\"model_2_3/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32) Tensor(\"model_2_3/inner_model/ExpandDims_1:0\", shape=(?, 400, 1), dtype=float32) Tensor(\"model_2_3/inner_model/Squeeze:0\", shape=(?, 32), dtype=float32)\n",
      "final_scores: Tensor(\"model_2_3/inner_model/target_weight/Sum:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"model_2_3/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32)\n",
      "Tensor(\"mul_3:0\", shape=(?, 32, 32), dtype=float32)\n",
      "Tensor(\"model_2_4/inner_model/time_distributed_5/Reshape_1:0\", shape=(?, 50, 400), dtype=float32) Tensor(\"model_2_4/inner_model/MatMul:0\", shape=(?, 50, 1), dtype=float32) Tensor(\"model_2_4/compute_masking/Cast:0\", shape=(?, 50), dtype=float32)\n",
      "weights: Tensor(\"model_2_4/inner_model/poly_attention/add:0\", shape=(?, 50, 32), dtype=float32)\n",
      "Tensor(\"model_2_4/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32) Tensor(\"model_2_4/inner_model/ExpandDims_1:0\", shape=(?, 400, 1), dtype=float32) Tensor(\"model_2_4/inner_model/Squeeze:0\", shape=(?, 32), dtype=float32)\n",
      "final_scores: Tensor(\"model_2_4/inner_model/target_weight/Sum:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"model_2_4/inner_model/poly_attention/MatMul_1:0\", shape=(?, 32, 400), dtype=float32)\n",
      "Tensor(\"mul_4:0\", shape=(?, 32, 32), dtype=float32)\n",
      "[<tf.Tensor 'Mean:0' shape=() dtype=float32>, <tf.Tensor 'Mean_1:0' shape=() dtype=float32>, <tf.Tensor 'Mean_2:0' shape=() dtype=float32>, <tf.Tensor 'Mean_3:0' shape=() dtype=float32>, <tf.Tensor 'Mean_4:0' shape=() dtype=float32>]\n",
      "Tensor(\"Mean_5:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "filter_num = 5\n",
    "tf.reset_default_graph()\n",
    "train_session = read_train_clickhistory(news_index,data_path,'train/train_behaviors.tsv',filter_num)\n",
    "train_user = parse_user(news_index,train_session)\n",
    "train_sess, train_user_id, train_label = get_train_input(news_index,train_session)\n",
    "\n",
    "train_generator = get_hir_train_generator(news_info,train_user['click'],train_user_id,train_sess,train_label,32)\n",
    "\n",
    "# test_session = read_test_clickhistory_noclk(news_index,data_path,'valid/test_behaviors.tsv')\n",
    "test_session = read_test_clickhistory(news_index,data_path,'valid/test_behaviors.tsv',filter_num)\n",
    "test_user = parse_user(news_index,test_session)\n",
    "\n",
    "test_docids, test_userids, test_labels, test_bound = get_test_input(news_index,test_session)\n",
    "\n",
    "model,inter_model = create_model(title_word_embedding_matrix,vert_embedding_matrix)\n",
    "\n",
    "# model.fit_generator(train_generator,epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75190/75190 [==============================] - 1137s 15ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4475c34661c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_docids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_userids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'click'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minter_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMRR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnDCG5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnDCG10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "test_generator = get_test_generator(news_info,test_docids,test_userids,test_user['click'],32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75190/75190 [==============================] - 1147s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_label = inter_model.predict_generator(test_generator,verbose=1)\n",
    "AUC, MRR, nDCG5, nDCG10 = evaluate(predicted_label,test_labels,test_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5348626878669376,\n",
       " 0.23450720535224118,\n",
       " 0.24081840515753591,\n",
       " 0.30832874011462047)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC, MRR, nDCG5, nDCG10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1977/5202 [==========>...................] - ETA: 21:20 - loss: 1.4007 - acc: 0.4301"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_83 (InputLayer)           [(None, 50, 31)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)             (None, 50, 30)       0           input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_84 (InputLayer)           [(None, 31)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_40 (TensorFlowO multiple             0           lambda_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)             (None, 30)           0           input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)             (None, 50)           0           input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)             (None,)              0           input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "compute_masking_30 (ComputeMask (None, 50)           0           tf_op_layer_Sum_40[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inner_model_25 (Inner_model)    ((None, 1), (None, 3 13339303    lambda_135[0][0]                 \n",
      "                                                                 lambda_136[0][0]                 \n",
      "                                                                 lambda_137[0][0]                 \n",
      "                                                                 lambda_138[0][0]                 \n",
      "                                                                 compute_masking_30[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 13,339,303\n",
      "Trainable params: 13,339,302\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inter_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62572/62572 [==============================] - 1244s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator = get_test_generator(news_info,test_docids,test_userids,test_user['click'],32)\n",
    "predicted_label,user_pre = inter_model.predict_generator(test_generator,verbose=1)\n",
    "AUC, MRR, nDCG5, nDCG10 = evaluate(predicted_label,test_labels,test_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6030782971591053, 0.270186198674874, 0.2910613348122594, 0.3542232368805076)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC, MRR, nDCG5, nDCG10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6563315963403435,\n",
       " 0.29815757640213525,\n",
       " 0.3289689743781696,\n",
       " 0.39233268253965664)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC1, MRR1, nDCG51, nDCG101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file+'filterHis_'+str(filter_num)+'.txt','a+') as f:\n",
    "    f.write(\"\\n-----------\\n\")    \n",
    "    f.write(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+\"\\n\")\n",
    "    f.write(str(AUC)+\" , \"+str(MRR)+\" , \"+str(nDCG5)+\" , \"+str(nDCG10)+\"\\n\\n\")\n",
    "    f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.672007502433353,\n",
       " 0.30463786151977684,\n",
       " 0.3390719191355297,\n",
       " 0.40566592619472813)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC, MRR, nDCG5, nDCG10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1983/62572 [..............................] - ETA: 17:07"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b4ea3ac7e5a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_docids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_userids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'click'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minter_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMRR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnDCG5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnDCG10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(x, y, sample_weights)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;31m# 1, 2, or 3-tuples from generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_generator = get_test_generator(news_info,test_docids,test_userids,test_user['click'],32)\n",
    "predicted_label = inter_model.predict_generator(test_generator,verbose=1)\n",
    "AUC, MRR, nDCG5, nDCG10 = evaluate(predicted_label,test_labels,test_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 5, 31)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 50, 31)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[0][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Tensor(\"lambda/strided_slice:0\", shape=(?, 50), dtype=int32) Tensor(\"lambda_1/strided_slice:0\", shape=(?,), dtype=int32)\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Tensor(\"embedding_1/embedding_lookup/Identity_1:0\", shape=(?, 50, 768), dtype=float32) Tensor(\"embedding_1_1/embedding_lookup/Identity_1:0\", shape=(?, 768), dtype=float32)\n",
      "Tensor(\"reshape/Reshape:0\", shape=(?, 50, 768), dtype=float32) Tensor(\"reshape_1/Reshape:0\", shape=(?, 768), dtype=float32) Tensor(\"lambda_2/strided_slice:0\", shape=(?, 50), dtype=int32) Tensor(\"lambda_3/strided_slice:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"embedding/embedding_lookup/Identity_1:0\", shape=(?, 50, 300), dtype=float32)\n",
      "Tensor(\"reshape_2/Reshape:0\", shape=(?, 50, 300), dtype=float32)\n",
      "Tensor(\"dot/Squeeze:0\", shape=(?, 50), dtype=float32)\n",
      "Tensor(\"dot/Squeeze:0\", shape=(?, 50), dtype=float32)\n",
      "Tensor(\"reshape_4/Reshape:0\", shape=(?, 50), dtype=float32)\n",
      "Tensor(\"reshape/Reshape:0\", shape=(?, 50, 768), dtype=float32) Tensor(\"softmax/Softmax:0\", shape=(?, 32, 50), dtype=float32)\n",
      "Tensor(\"dot_1/MatMul:0\", shape=(?, 32, 768), dtype=float32)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 50, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50)           0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None,)              0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 50)           0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           multiple             5700        lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         multiple             50103552    lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, None, 300)    0           embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 768)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50, 300)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 300)]        0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 200)      153600      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 50)           0           reshape_2[0][0]                  \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50, 32)       6400        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 50)           0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 32, 50)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 32, 50)       0           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None,)              0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 50)       0           permute[0][0]                    \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 32, 50)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 768)          0           embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 32, 768)      0           softmax[0][0]                    \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 768)          589824      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 32)           0           dot_1[0][0]                      \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 32)           0           dot_1[0][0]                      \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 32)           0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 1)            0           dot_3[0][0]                      \n",
      "                                                                 softmax_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 50,859,076\n",
      "Trainable params: 749,824\n",
      "Non-trainable params: 50,109,252\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 50, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50)           0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None,)              0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 50)           0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           multiple             5700        lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         multiple             50103552    lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, None, 300)    0           embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 768)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50, 300)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 300)]        0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 200)      153600      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 50)           0           reshape_2[0][0]                  \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50, 32)       6400        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 50)           0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 32, 50)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 32, 50)       0           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 50)       0           permute[0][0]                    \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 32, 50)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 32, 768)      0           softmax[0][0]                    \n",
      "                                                                 reshape[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,269,252\n",
      "Trainable params: 160,000\n",
      "Non-trainable params: 50,109,252\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"l2_normalize:0\", shape=(?, 32, 768), dtype=float32)\n",
      "Tensor(\"dot_5/MatMul:0\", shape=(?, 32, 32), dtype=float32)\n",
      "Tensor(\"l2_normalize_1:0\", shape=(?, 32, 768), dtype=float32)\n",
      "Tensor(\"dot_6/MatMul:0\", shape=(?, 32, 32), dtype=float32)\n",
      "Tensor(\"l2_normalize_2:0\", shape=(?, 32, 768), dtype=float32)\n",
      "Tensor(\"dot_7/MatMul:0\", shape=(?, 32, 32), dtype=float32)\n",
      "Tensor(\"l2_normalize_3:0\", shape=(?, 32, 768), dtype=float32)\n",
      "Tensor(\"dot_8/MatMul:0\", shape=(?, 32, 32), dtype=float32)\n",
      "Tensor(\"l2_normalize_4:0\", shape=(?, 32, 768), dtype=float32)\n",
      "Tensor(\"dot_9/MatMul:0\", shape=(?, 32, 32), dtype=float32)\n",
      "[<tf.Tensor 'Mean:0' shape=(?,) dtype=float32>, <tf.Tensor 'Mean_1:0' shape=(?,) dtype=float32>, <tf.Tensor 'Mean_2:0' shape=(?,) dtype=float32>, <tf.Tensor 'Mean_3:0' shape=(?,) dtype=float32>, <tf.Tensor 'Mean_4:0' shape=(?,) dtype=float32>]\n",
      "Tensor(\"Mean_5:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model,inter_model = create_model(News_pre_emd,vert_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array([[[32187,    11],\n",
      "        [37210,    11],\n",
      "        [43907,     6],\n",
      "        [35307,     3],\n",
      "        [41306,     3]],\n",
      "\n",
      "       [[ 5767,     1],\n",
      "        [43459,     3],\n",
      "        [38863,     5],\n",
      "        [12325,     1],\n",
      "        [ 5119,     1]],\n",
      "\n",
      "       [[50715,    14],\n",
      "        [50022,    11],\n",
      "        [50022,    11],\n",
      "        [50689,     3],\n",
      "        [50689,     3]],\n",
      "\n",
      "       [[33788,     3],\n",
      "        [44751,     3],\n",
      "        [31917,     3],\n",
      "        [44751,     3],\n",
      "        [49384,     3]],\n",
      "\n",
      "       [[41551,     3],\n",
      "        [31917,     3],\n",
      "        [31917,     3],\n",
      "        [49384,     3],\n",
      "        [49384,     3]],\n",
      "\n",
      "       [[28461,     6],\n",
      "        [45573,     4],\n",
      "        [48455,     4],\n",
      "        [42487,     3],\n",
      "        [35139,     3]],\n",
      "\n",
      "       [[41884,     3],\n",
      "        [37034,     3],\n",
      "        [36333,     3],\n",
      "        [43039,    11],\n",
      "        [37034,     3]],\n",
      "\n",
      "       [[45975,    10],\n",
      "        [33900,     4],\n",
      "        [33900,     4],\n",
      "        [33900,     4],\n",
      "        [33900,     4]],\n",
      "\n",
      "       [[42484,     4],\n",
      "        [51200,     1],\n",
      "        [42697,     6],\n",
      "        [31290,     9],\n",
      "        [39830,     1]],\n",
      "\n",
      "       [[32766,     1],\n",
      "        [46427,     3],\n",
      "        [33751,     4],\n",
      "        [42267,     3],\n",
      "        [37662,    11]],\n",
      "\n",
      "       [[34429,    10],\n",
      "        [32603,     3],\n",
      "        [43960,     8],\n",
      "        [41349,    11],\n",
      "        [36333,     3]],\n",
      "\n",
      "       [[49493,     4],\n",
      "        [24238,     1],\n",
      "        [48780,     3],\n",
      "        [51275,     3],\n",
      "        [49688,    11]],\n",
      "\n",
      "       [[42167,    14],\n",
      "        [38971,     3],\n",
      "        [36650,     3],\n",
      "        [50603,    10],\n",
      "        [49209,     1]],\n",
      "\n",
      "       [[39967,     8],\n",
      "        [49209,     1],\n",
      "        [32961,    11],\n",
      "        [40107,    11],\n",
      "        [36650,     3]],\n",
      "\n",
      "       [[35307,     3],\n",
      "        [37098,     2],\n",
      "        [46622,     3],\n",
      "        [34797,     8],\n",
      "        [ 6642,     2]],\n",
      "\n",
      "       [[36808,     2],\n",
      "        [ 1639,     3],\n",
      "        [27812,     6],\n",
      "        [39151,     4],\n",
      "        [45956,     2]],\n",
      "\n",
      "       [[33378,     3],\n",
      "        [41868,     3],\n",
      "        [44041,     3],\n",
      "        [45568,     3],\n",
      "        [42377,     3]],\n",
      "\n",
      "       [[51200,     1],\n",
      "        [49720,     3],\n",
      "        [40734,     9],\n",
      "        [38645,     2],\n",
      "        [16126,    12]],\n",
      "\n",
      "       [[36032,     3],\n",
      "        [13625,     5],\n",
      "        [18596,     1],\n",
      "        [50747,     3],\n",
      "        [44330,     2]],\n",
      "\n",
      "       [[50689,     3],\n",
      "        [39227,     1],\n",
      "        [34884,     1],\n",
      "        [45765,     9],\n",
      "        [ 8677,     8]],\n",
      "\n",
      "       [[38897,     4],\n",
      "        [41381,     9],\n",
      "        [32675,    14],\n",
      "        [46625,    12],\n",
      "        [ 8597,    10]],\n",
      "\n",
      "       [[35691,     2],\n",
      "        [  458,     1],\n",
      "        [42784,     8],\n",
      "        [40840,     8],\n",
      "        [ 6590,     2]],\n",
      "\n",
      "       [[22968,     3],\n",
      "        [34600,    10],\n",
      "        [36747,     3],\n",
      "        [39882,    14],\n",
      "        [43868,     3]],\n",
      "\n",
      "       [[46640,     9],\n",
      "        [42475,     1],\n",
      "        [27812,     6],\n",
      "        [45558,     8],\n",
      "        [31324,     6]],\n",
      "\n",
      "       [[47804,     4],\n",
      "        [50760,     7],\n",
      "        [42267,     3],\n",
      "        [35497,     9],\n",
      "        [17280,     6]],\n",
      "\n",
      "       [[34907,     7],\n",
      "        [47527,     3],\n",
      "        [31749,     6],\n",
      "        [37675,     3],\n",
      "        [33088,    13]],\n",
      "\n",
      "       [[35093,    10],\n",
      "        [16140,    11],\n",
      "        [37518,    11],\n",
      "        [39220,     3],\n",
      "        [38700,    13]],\n",
      "\n",
      "       [[47096,    14],\n",
      "        [42942,     9],\n",
      "        [43010,     3],\n",
      "        [37518,    11],\n",
      "        [41161,     3]],\n",
      "\n",
      "       [[37098,     2],\n",
      "        [16140,    11],\n",
      "        [23607,     1],\n",
      "        [33169,     9],\n",
      "        [20491,     1]],\n",
      "\n",
      "       [[33324,    14],\n",
      "        [50203,     1],\n",
      "        [31666,     6],\n",
      "        [48698,     6],\n",
      "        [49583,    14]],\n",
      "\n",
      "       [[31705,    14],\n",
      "        [31666,     6],\n",
      "        [45454,     3],\n",
      "        [50471,     3],\n",
      "        [49962,     5]],\n",
      "\n",
      "       [[33900,     4],\n",
      "        [50689,     3],\n",
      "        [36625,    11],\n",
      "        [50022,    11],\n",
      "        [51149,     4]],\n",
      "\n",
      "       [[32603,     3],\n",
      "        [31222,     1],\n",
      "        [31222,     1],\n",
      "        [31222,     1],\n",
      "        [31222,     1]],\n",
      "\n",
      "       [[41884,     3],\n",
      "        [35167,     1],\n",
      "        [37083,     1],\n",
      "        [37364,    14],\n",
      "        [42880,     5]],\n",
      "\n",
      "       [[49781,     3],\n",
      "        [45032,     3],\n",
      "        [16140,    11],\n",
      "        [32498,    13],\n",
      "        [43694,     4]],\n",
      "\n",
      "       [[ 5680,     9],\n",
      "        [35848,     3],\n",
      "        [32363,     1],\n",
      "        [47008,     3],\n",
      "        [31749,     6]],\n",
      "\n",
      "       [[50366,    14],\n",
      "        [33378,     3],\n",
      "        [45450,     3],\n",
      "        [45450,     3],\n",
      "        [45450,     3]],\n",
      "\n",
      "       [[10730,     3],\n",
      "        [41296,     3],\n",
      "        [41068,     3],\n",
      "        [40153,     4],\n",
      "        [36747,     3]],\n",
      "\n",
      "       [[31348,     1],\n",
      "        [50689,     3],\n",
      "        [40243,     9],\n",
      "        [32001,     3],\n",
      "        [51152,     3]],\n",
      "\n",
      "       [[35582,    12],\n",
      "        [49350,    10],\n",
      "        [33872,     4],\n",
      "        [33933,    12],\n",
      "        [41509,     6]],\n",
      "\n",
      "       [[31523,     8],\n",
      "        [40243,     9],\n",
      "        [32363,     1],\n",
      "        [31710,    14],\n",
      "        [49840,     7]],\n",
      "\n",
      "       [[49534,     4],\n",
      "        [41551,     3],\n",
      "        [41551,     3],\n",
      "        [41551,     3],\n",
      "        [41551,     3]],\n",
      "\n",
      "       [[50689,     3],\n",
      "        [17646,     2],\n",
      "        [31348,     1],\n",
      "        [48418,     9],\n",
      "        [51016,     3]],\n",
      "\n",
      "       [[46800,     7],\n",
      "        [38078,     1],\n",
      "        [42459,     3],\n",
      "        [34515,     3],\n",
      "        [32148,     7]],\n",
      "\n",
      "       [[32961,    11],\n",
      "        [47388,     4],\n",
      "        [38391,     9],\n",
      "        [36835,     3],\n",
      "        [34491,     8]],\n",
      "\n",
      "       [[44548,     1],\n",
      "        [ 3752,     1],\n",
      "        [40378,     7],\n",
      "        [42377,     3],\n",
      "        [46472,    11]],\n",
      "\n",
      "       [[41551,     3],\n",
      "        [48698,     6],\n",
      "        [48698,     6],\n",
      "        [48698,     6],\n",
      "        [48698,     6]],\n",
      "\n",
      "       [[37266,     4],\n",
      "        [42475,     1],\n",
      "        [38997,    11],\n",
      "        [40917,     3],\n",
      "        [45630,     3]],\n",
      "\n",
      "       [[48382,     2],\n",
      "        [36428,    11],\n",
      "        [42880,     5],\n",
      "        [35167,     1],\n",
      "        [33933,    12]],\n",
      "\n",
      "       [[40914,     1],\n",
      "        [38126,     4],\n",
      "        [32717,     9],\n",
      "        [37958,     3],\n",
      "        [49953,     6]],\n",
      "\n",
      "       [[50768,    14],\n",
      "        [38254,     2],\n",
      "        [33187,     7],\n",
      "        [49953,     6],\n",
      "        [31796,    14]],\n",
      "\n",
      "       [[47145,     1],\n",
      "        [38254,     2],\n",
      "        [42175,    11],\n",
      "        [31796,    14],\n",
      "        [51161,     3]],\n",
      "\n",
      "       [[40457,     3],\n",
      "        [48030,    11],\n",
      "        [ 5764,    10],\n",
      "        [49099,     3],\n",
      "        [47398,    13]],\n",
      "\n",
      "       [[41306,     3],\n",
      "        [41983,    11],\n",
      "        [31710,    14],\n",
      "        [35653,     4],\n",
      "        [43940,     4]],\n",
      "\n",
      "       [[32931,    11],\n",
      "        [37214,    11],\n",
      "        [36660,     1],\n",
      "        [40107,    11],\n",
      "        [36783,    11]],\n",
      "\n",
      "       [[49099,     3],\n",
      "        [40774,     4],\n",
      "        [48582,    10],\n",
      "        [36437,    11],\n",
      "        [37610,     8]],\n",
      "\n",
      "       [[40219,     3],\n",
      "        [37664,     3],\n",
      "        [39356,    10],\n",
      "        [31446,     2],\n",
      "        [20114,     1]],\n",
      "\n",
      "       [[45681,     4],\n",
      "        [42377,     3],\n",
      "        [40473,     3],\n",
      "        [36809,     3],\n",
      "        [39989,     4]],\n",
      "\n",
      "       [[45458,     4],\n",
      "        [42220,    14],\n",
      "        [42377,     3],\n",
      "        [38978,    11],\n",
      "        [46061,     3]],\n",
      "\n",
      "       [[33378,     3],\n",
      "        [42377,     3],\n",
      "        [45568,     3],\n",
      "        [42220,    14],\n",
      "        [46061,     3]],\n",
      "\n",
      "       [[ 5828,    11],\n",
      "        [48960,     8],\n",
      "        [33407,     3],\n",
      "        [46758,     1],\n",
      "        [  765,     8]],\n",
      "\n",
      "       [[36333,     3],\n",
      "        [31222,     1],\n",
      "        [41884,     3],\n",
      "        [32603,     3],\n",
      "        [32675,    14]],\n",
      "\n",
      "       [[41551,     3],\n",
      "        [47533,    14],\n",
      "        [49406,     4],\n",
      "        [45454,     3],\n",
      "        [37718,     3]],\n",
      "\n",
      "       [[35307,     3],\n",
      "        [44542,     3],\n",
      "        [35417,    11],\n",
      "        [35848,     3],\n",
      "        [33175,     3]]], dtype=int32), array([[[10970,     3],\n",
      "        [  129,     9],\n",
      "        [19188,    14],\n",
      "        ...,\n",
      "        [33753,     3],\n",
      "        [40662,     3],\n",
      "        [34840,     4]],\n",
      "\n",
      "       [[    0,     0],\n",
      "        [    0,     0],\n",
      "        [    0,     0],\n",
      "        ...,\n",
      "        [28654,     7],\n",
      "        [ 9943,     1],\n",
      "        [31348,     1]],\n",
      "\n",
      "       [[    0,     0],\n",
      "        [    0,     0],\n",
      "        [    0,     0],\n",
      "        ...,\n",
      "        [27280,     4],\n",
      "        [17200,    13],\n",
      "        [29788,     4]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[    0,     0],\n",
      "        [    0,     0],\n",
      "        [    0,     0],\n",
      "        ...,\n",
      "        [ 2078,     3],\n",
      "        [21110,    11],\n",
      "        [21081,     4]],\n",
      "\n",
      "       [[    0,     0],\n",
      "        [    0,     0],\n",
      "        [    0,     0],\n",
      "        ...,\n",
      "        [21731,     4],\n",
      "        [45654,    11],\n",
      "        [37544,     3]],\n",
      "\n",
      "       [[    0,     0],\n",
      "        [    0,     0],\n",
      "        [    0,     0],\n",
      "        ...,\n",
      "        [19731,     6],\n",
      "        [20522,    10],\n",
      "        [19212,    10]]], dtype=int32)], [array([[1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.]])])\n"
     ]
    }
   ],
   "source": [
    "for d in train_generator:\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2389/2601 [==========================>...] - ETA: 2s - loss: 5.9441 - acc: 0.2612"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2d774efae81a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/reco_gpu/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1.fit_generator(train_generator,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entity_emb_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-3311dab6fe75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnews_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minter_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle_word_embedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mentity_emb_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnews_scoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'entity_emb_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "model,news_encoder,inter_model, = create_model(title_word_embedding_matrix,entity_emb_matrix,category_dict)\n",
    "\n",
    "model.fit_generator(train_generator,epochs=3)\n",
    "\n",
    "news_scoring = news_encoder.predict(news_info,verbose=1)\n",
    "test_generator = get_test_generator(news_scoring,test_docids,test_userids,test_user['click'],64)\n",
    "predicted_label = inter_model.predict_generator(test_generator,verbose=1)\n",
    "\n",
    "# parse_result(predicted_label,test_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31286/31286 [==============================] - 62s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# news_scoring = news_encoder.predict(news_info,verbose=1)\n",
    "test_generator = get_test_generator(news_info,test_docids,test_userids,test_user['click'],64)\n",
    "predicted_label = inter_model.predict_generator(test_generator,verbose=1)\n",
    "evaluate(predicted_label,test_labels,test_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5511172573882699,\n",
       " 0.23002345951023195,\n",
       " 0.24317682365615745,\n",
       " 0.3057768483287554)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2601/2601 [==============================] - 426s 164ms/step - loss: 1.3046 - acc: 0.4672\n",
      "Epoch 2/2\n",
      "2601/2601 [==============================] - 427s 164ms/step - loss: 1.2898 - acc: 0.4744\n",
      "65239/65239 [==============================] - 7s 101us/sample\n",
      "31286/31286 [==============================] - 255s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,epochs=2)\n",
    "\n",
    "news_scoring = news_encoder.predict(news_info,verbose=1)\n",
    "test_generator = get_test_generator(news_scoring,test_docids,test_userids,test_user['click'],64)\n",
    "predicted_label = inter_model.predict_generator(test_generator,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6782388971248503,\n",
       " 0.31140355177233714,\n",
       " 0.34537388579792777,\n",
       " 0.410167162906963)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(predicted_label,test_labels,test_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2601/2601 [==============================] - 423s 162ms/step - loss: 1.2770 - acc: 0.4817\n",
      "Epoch 2/2\n",
      "2601/2601 [==============================] - 430s 165ms/step - loss: 1.2649 - acc: 0.4865\n",
      "65239/65239 [==============================] - 7s 100us/sample\n",
      "31286/31286 [==============================] - 267s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,epochs=2)\n",
    "\n",
    "news_scoring = news_encoder.predict(news_info,verbose=1)\n",
    "test_generator = get_test_generator(news_scoring,test_docids,test_userids,test_user['click'],64)\n",
    "predicted_label = inter_model.predict_generator(test_generator,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6783414368082672,\n",
       " 0.3061077266362954,\n",
       " 0.3414165614339723,\n",
       " 0.4076276224695856)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(predicted_label,test_labels,test_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_gpu)",
   "language": "python",
   "name": "reco_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "182.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "287.86px",
    "left": "793.636px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
